{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report (wrangle_report) on Wrangle and Analyze Data project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Created by Akbarali Mukhammadiev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In today's world, it is said that the real_world data rarely comes clean and it is completely true. Thus, in order to be a professional data analyst, it is utmost important to possess skills like data wrangling, assessing, cleaning and visualizing. While, working on this project, I was able to improve exactly these skills of mine and put the next step towards to become a professional data analyst. The steps that I took in the wrangling process are as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taken steps and details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Data gathering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data gathering step, I was required all three pieces of data as described in the \"Data Gathering\" section in the `wrangle_act.ipynb` notebook. I was already given a file `twitter_archive_enhanced.csv` to download manually. I downloaded it, then uploaded it and read the data into a pandas DataFrame using pandas `.read_csv()` function. The second dataset `image_predictions.tsv` was given to download programmatically. I performed the task using Python's `Requests` library. Finally, the third dataset was required to download from Twitter with (at minimum) tweet ID, retweet count, and favorite count. I performed this task using twitter API keys from my twitter developer account and Python's `Tweepy` library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Data assesing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data assessing step, after gathering all three pieces of data, assess them visually and programmatically for quality and tidiness issues. I detected and documented eight quality issues and two tidiness issues in the corresponding \"Accessing Data\" section in the `wrangle_act.ipynb` Jupyter Notebook as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Data cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data cleaning step, I cleaned all of the issues I documented while assessing. I performed this cleaning in the corresponding \"Cleaning Data\" section in the `wrangle_act.ipynb`.\n",
    "\n",
    "I completed the following items in this step.\n",
    "\n",
    "    1. Before cleaning, I created a copy of the each original data.\n",
    "    2. During cleaning, I used the define-code-test framework and clearly documented them.\n",
    "    3. Finally I merged all of the three datasets and saved them as a single tidy master pandas DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Data storing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data storing step, I followed the corresponding \"Storing Data\" section in the `wrangle_act.ipynb` notebook, I stored the cleaned master DataFrame in a CSV file with the main one named `twitter_archive_master.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Data analyzing and visualizing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data Analyzing and Visualizing step, in the same corresponding section in my `wrangle_act.ipynb` Jupyter Notebook, I analyzed and visualized the wrangled data. I produced three insights and one visualization as it was required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Data reporting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final data reporting step, I created a 300-600 word written report called `wrangle_report.html` (current) that briefly describes my wrangling efforts. Moreover, I created a 250-word-minimum written report called `act_report.html` that communicates all the insights and displays the visualization produced from the wrangled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I have mentioned above, this project was really helpful to step up as a future data analyst. Through this project, I was introduced to the new functions and methods in Python, Numpy, Pandas, Matplotlib, Excel and SQL tools and libraries. Furthermore, I learned how to use twitter APIs in order to gather data and also how to download and extract data from online data sourses and web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'wrangle_report.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
